{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN for crustal and lithospheric configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst ANNs are difficult to interpret, they provide great accuracy metrics in a variety of examples. Here, we will see how they perform on this configuration training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import numpy as np\n",
    "import math as m\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x (km)</th>\n",
       "      <th>Airy anom (mGal)</th>\n",
       "      <th>Bouguer anom (mGal)</th>\n",
       "      <th>Geoid anom (mGal)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1991.183919</td>\n",
       "      <td>0.254370</td>\n",
       "      <td>-13.811054</td>\n",
       "      <td>-1.701378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1158.191535</td>\n",
       "      <td>24.654458</td>\n",
       "      <td>41.233023</td>\n",
       "      <td>32.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>73.740000</td>\n",
       "      <td>-49.369000</td>\n",
       "      <td>-106.680000</td>\n",
       "      <td>-87.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1028.550000</td>\n",
       "      <td>-14.855500</td>\n",
       "      <td>-31.447250</td>\n",
       "      <td>-11.340750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1991.285000</td>\n",
       "      <td>0.626500</td>\n",
       "      <td>-3.374000</td>\n",
       "      <td>-4.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2939.055000</td>\n",
       "      <td>15.243500</td>\n",
       "      <td>10.118000</td>\n",
       "      <td>6.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3965.210000</td>\n",
       "      <td>56.109000</td>\n",
       "      <td>57.201000</td>\n",
       "      <td>73.660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x (km)  Airy anom (mGal)  Bouguer anom (mGal)  Geoid anom (mGal)\n",
       "count    74.000000         74.000000            74.000000          74.000000\n",
       "mean   1991.183919          0.254370           -13.811054          -1.701378\n",
       "std    1158.191535         24.654458            41.233023          32.449100\n",
       "min      73.740000        -49.369000          -106.680000         -87.201000\n",
       "25%    1028.550000        -14.855500           -31.447250         -11.340750\n",
       "50%    1991.285000          0.626500            -3.374000          -4.345000\n",
       "75%    2939.055000         15.243500            10.118000           6.677000\n",
       "max    3965.210000         56.109000            57.201000          73.660000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in raw data.\n",
    "anom_df = pd.read_csv(\"bag_anom.csv\")\n",
    "anom_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x (km)</th>\n",
       "      <th>Airy anom (mGal)</th>\n",
       "      <th>Bouguer anom (mGal)</th>\n",
       "      <th>Geoid anom (mGal)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.74</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-3.561</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.94</td>\n",
       "      <td>-4.957</td>\n",
       "      <td>-4.776</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.99</td>\n",
       "      <td>-7.785</td>\n",
       "      <td>-7.758</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225.63</td>\n",
       "      <td>-13.608</td>\n",
       "      <td>-13.694</td>\n",
       "      <td>1.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261.35</td>\n",
       "      <td>-24.128</td>\n",
       "      <td>-24.250</td>\n",
       "      <td>4.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x (km)  Airy anom (mGal)  Bouguer anom (mGal)  Geoid anom (mGal)\n",
       "0   73.74            -3.537               -3.561              0.280\n",
       "1  127.94            -4.957               -4.776              0.331\n",
       "2  178.99            -7.785               -7.758              0.903\n",
       "3  225.63           -13.608              -13.694              1.852\n",
       "4  261.35           -24.128              -24.250              4.820"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different types correspond to the diagram in the report.\n",
    "# Here we use a one hot encoding style for use in the ANN.\n",
    "anom_df['Type1'] = anom_df['x (km)'].apply(func = (lambda x: 1 if 300.0 <= x <= 600.0 else 0))\n",
    "anom_df['Type2'] = anom_df['x (km)'].apply(func = (lambda x: 1 if 1000.0 <= x <= 1300.0 else 0))\n",
    "anom_df['Type3'] = anom_df['x (km)'].apply(func = (lambda x: 1 if 1700.0 <= x <= 2000.0 else 0))\n",
    "anom_df['Type4'] = anom_df['x (km)'].apply(func = (lambda x: 1 if 2400.0 <= x <= 2700.0 else 0))\n",
    "anom_df['Type5'] = anom_df['x (km)'].apply(func = (lambda x: 1 if 3200.0 <= x <= 3500.0 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type6 is the reference configuration with no lithospheric changes.\n",
    "type_list = ['Type1','Type2','Type3','Type4','Type5']\n",
    "anom_df['Type6'] = anom_df[type_list].sum(axis = 1)\n",
    "anom_df['Type6'] = anom_df['Type6'].apply(func = (lambda x: 1 if x == 0 else 0))\n",
    "type_list.append('Type6')\n",
    "output_length = len(type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x (km)</th>\n",
       "      <th>Airy anom (mGal)</th>\n",
       "      <th>Bouguer anom (mGal)</th>\n",
       "      <th>Geoid anom (mGal)</th>\n",
       "      <th>Type1</th>\n",
       "      <th>Type2</th>\n",
       "      <th>Type3</th>\n",
       "      <th>Type4</th>\n",
       "      <th>Type5</th>\n",
       "      <th>Type6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.74</td>\n",
       "      <td>-3.537</td>\n",
       "      <td>-3.561</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127.94</td>\n",
       "      <td>-4.957</td>\n",
       "      <td>-4.776</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.99</td>\n",
       "      <td>-7.785</td>\n",
       "      <td>-7.758</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225.63</td>\n",
       "      <td>-13.608</td>\n",
       "      <td>-13.694</td>\n",
       "      <td>1.852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261.35</td>\n",
       "      <td>-24.128</td>\n",
       "      <td>-24.250</td>\n",
       "      <td>4.820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x (km)  Airy anom (mGal)  Bouguer anom (mGal)  Geoid anom (mGal)  Type1  \\\n",
       "0   73.74            -3.537               -3.561              0.280      0   \n",
       "1  127.94            -4.957               -4.776              0.331      0   \n",
       "2  178.99            -7.785               -7.758              0.903      0   \n",
       "3  225.63           -13.608              -13.694              1.852      0   \n",
       "4  261.35           -24.128              -24.250              4.820      0   \n",
       "\n",
       "   Type2  Type3  Type4  Type5  Type6  \n",
       "0      0      0      0      0      1  \n",
       "1      0      0      0      0      1  \n",
       "2      0      0      0      0      1  \n",
       "3      0      0      0      0      1  \n",
       "4      0      0      0      0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = ['Airy anom (mGal)', 'Bouguer anom (mGal)', 'Geoid anom (mGal)']\n",
    "scaler = StandardScaler()\n",
    "X_values = scaler.fit_transform(anom_df[input_list])\n",
    "y_labels = anom_df[type_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_values,\n",
    "                                                    y_labels,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(units = 50, input_dim = len(input_list), activation = 'relu', name = 'hidden_layer_1'))\n",
    "keras_model.add(Dropout(rate = 0.25))\n",
    "keras_model.add(Dense(units = 50, activation = 'relu', name = 'hidden_layer_2'))\n",
    "keras_model.add(Dropout(rate = 0.25))\n",
    "keras_model.add(Dense(units = output_length, activation = 'softmax', name = 'output_layer'))\n",
    "keras_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "                                                         loss = 'categorical_crossentropy',\n",
    "                                                         metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.8908 - accuracy: 0.1224 - val_loss: 1.8033 - val_accuracy: 0.1600\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8244 - accuracy: 0.2653 - val_loss: 1.7779 - val_accuracy: 0.2800\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7893 - accuracy: 0.3265 - val_loss: 1.7522 - val_accuracy: 0.4400\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7498 - accuracy: 0.4694 - val_loss: 1.7268 - val_accuracy: 0.4400\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6839 - accuracy: 0.6735 - val_loss: 1.7020 - val_accuracy: 0.6000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7311 - accuracy: 0.6122 - val_loss: 1.6785 - val_accuracy: 0.6000\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6602 - accuracy: 0.6939 - val_loss: 1.6548 - val_accuracy: 0.6000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6551 - accuracy: 0.6735 - val_loss: 1.6309 - val_accuracy: 0.6000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6056 - accuracy: 0.7143 - val_loss: 1.6072 - val_accuracy: 0.6000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6106 - accuracy: 0.6735 - val_loss: 1.5826 - val_accuracy: 0.6000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5441 - accuracy: 0.6735 - val_loss: 1.5568 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5158 - accuracy: 0.7347 - val_loss: 1.5313 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5048 - accuracy: 0.7551 - val_loss: 1.5054 - val_accuracy: 0.6000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4740 - accuracy: 0.7347 - val_loss: 1.4783 - val_accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4192 - accuracy: 0.7551 - val_loss: 1.4511 - val_accuracy: 0.6000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4448 - accuracy: 0.7143 - val_loss: 1.4241 - val_accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3706 - accuracy: 0.7347 - val_loss: 1.3971 - val_accuracy: 0.6000\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3663 - accuracy: 0.7347 - val_loss: 1.3702 - val_accuracy: 0.6000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2995 - accuracy: 0.7551 - val_loss: 1.3427 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2553 - accuracy: 0.7143 - val_loss: 1.3159 - val_accuracy: 0.6000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2503 - accuracy: 0.7143 - val_loss: 1.2882 - val_accuracy: 0.6000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.2192 - accuracy: 0.7347 - val_loss: 1.2593 - val_accuracy: 0.6000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1949 - accuracy: 0.7143 - val_loss: 1.2302 - val_accuracy: 0.6000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1014 - accuracy: 0.7755 - val_loss: 1.2022 - val_accuracy: 0.6000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1314 - accuracy: 0.7347 - val_loss: 1.1758 - val_accuracy: 0.6000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0845 - accuracy: 0.7347 - val_loss: 1.1499 - val_accuracy: 0.6000\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0751 - accuracy: 0.7347 - val_loss: 1.1238 - val_accuracy: 0.6000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0519 - accuracy: 0.7551 - val_loss: 1.0973 - val_accuracy: 0.6400\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.9230 - accuracy: 0.8367 - val_loss: 1.0716 - val_accuracy: 0.6400\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9414 - accuracy: 0.7959 - val_loss: 1.0453 - val_accuracy: 0.7200\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.9755 - accuracy: 0.7551 - val_loss: 1.0194 - val_accuracy: 0.7200\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9014 - accuracy: 0.7347 - val_loss: 0.9945 - val_accuracy: 0.7200\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8888 - accuracy: 0.7551 - val_loss: 0.9690 - val_accuracy: 0.7200\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8564 - accuracy: 0.7959 - val_loss: 0.9444 - val_accuracy: 0.7600\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8093 - accuracy: 0.7959 - val_loss: 0.9208 - val_accuracy: 0.7600\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8055 - accuracy: 0.7959 - val_loss: 0.8971 - val_accuracy: 0.7600\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7636 - accuracy: 0.8163 - val_loss: 0.8741 - val_accuracy: 0.7600\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.7268 - accuracy: 0.8163 - val_loss: 0.8520 - val_accuracy: 0.7600\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7431 - accuracy: 0.7959 - val_loss: 0.8297 - val_accuracy: 0.7600\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7159 - accuracy: 0.7959 - val_loss: 0.8068 - val_accuracy: 0.7600\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6664 - accuracy: 0.8571 - val_loss: 0.7841 - val_accuracy: 0.7600\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6013 - accuracy: 0.7959 - val_loss: 0.7635 - val_accuracy: 0.7600\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.7959 - val_loss: 0.7436 - val_accuracy: 0.7600\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6754 - accuracy: 0.7959 - val_loss: 0.7246 - val_accuracy: 0.7600\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6229 - accuracy: 0.8367 - val_loss: 0.7066 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6100 - accuracy: 0.8367 - val_loss: 0.6884 - val_accuracy: 0.8800\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5847 - accuracy: 0.8163 - val_loss: 0.6694 - val_accuracy: 0.8800\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4873 - accuracy: 0.8163 - val_loss: 0.6513 - val_accuracy: 0.8800\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5575 - accuracy: 0.8776 - val_loss: 0.6335 - val_accuracy: 0.8800\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4868 - accuracy: 0.8571 - val_loss: 0.6164 - val_accuracy: 0.8800\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4262 - accuracy: 0.9184 - val_loss: 0.5993 - val_accuracy: 0.8800\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.8571 - val_loss: 0.5830 - val_accuracy: 0.8800\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4805 - accuracy: 0.8571 - val_loss: 0.5674 - val_accuracy: 0.8800\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.8776 - val_loss: 0.5531 - val_accuracy: 0.8800\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4675 - accuracy: 0.8571 - val_loss: 0.5399 - val_accuracy: 0.8800\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4606 - accuracy: 0.8571 - val_loss: 0.5263 - val_accuracy: 0.8800\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4359 - accuracy: 0.8163 - val_loss: 0.5141 - val_accuracy: 0.8800\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4063 - accuracy: 0.9184 - val_loss: 0.5018 - val_accuracy: 0.8800\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3689 - accuracy: 0.9184 - val_loss: 0.4895 - val_accuracy: 0.9200\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.3895 - accuracy: 0.8776 - val_loss: 0.4779 - val_accuracy: 0.9200\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3863 - accuracy: 0.8571 - val_loss: 0.4659 - val_accuracy: 0.9200\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3438 - accuracy: 0.8776 - val_loss: 0.4544 - val_accuracy: 0.9200\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4179 - accuracy: 0.8980 - val_loss: 0.4433 - val_accuracy: 0.9200\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3233 - accuracy: 0.8980 - val_loss: 0.4331 - val_accuracy: 0.9200\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3670 - accuracy: 0.8776 - val_loss: 0.4233 - val_accuracy: 0.9200\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3124 - accuracy: 0.8571 - val_loss: 0.4141 - val_accuracy: 0.9200\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3043 - accuracy: 0.8776 - val_loss: 0.4055 - val_accuracy: 0.9200\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2546 - accuracy: 0.9592 - val_loss: 0.3980 - val_accuracy: 0.9200\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4029 - accuracy: 0.8571 - val_loss: 0.3896 - val_accuracy: 0.9600\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4121 - accuracy: 0.8367 - val_loss: 0.3808 - val_accuracy: 0.9600\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3078 - accuracy: 0.9184 - val_loss: 0.3730 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2999 - accuracy: 0.8980 - val_loss: 0.3664 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2742 - accuracy: 0.9184 - val_loss: 0.3602 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2386 - accuracy: 0.9796 - val_loss: 0.3545 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2353 - accuracy: 0.9388 - val_loss: 0.3489 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2655 - accuracy: 0.9184 - val_loss: 0.3430 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2810 - accuracy: 0.9184 - val_loss: 0.3373 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2507 - accuracy: 0.9592 - val_loss: 0.3312 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2257 - accuracy: 0.9388 - val_loss: 0.3243 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2597 - accuracy: 0.8980 - val_loss: 0.3178 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2880 - accuracy: 0.8980 - val_loss: 0.3115 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1920 - accuracy: 0.9796 - val_loss: 0.3059 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2166 - accuracy: 0.9388 - val_loss: 0.3010 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2347 - accuracy: 0.8980 - val_loss: 0.2969 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2143 - accuracy: 0.9184 - val_loss: 0.2929 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2150 - accuracy: 0.9388 - val_loss: 0.2895 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1837 - accuracy: 0.9592 - val_loss: 0.2862 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1993 - accuracy: 0.9592 - val_loss: 0.2828 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2176 - accuracy: 0.9592 - val_loss: 0.2791 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2055 - accuracy: 0.9592 - val_loss: 0.2748 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2311 - accuracy: 0.8776 - val_loss: 0.2696 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1617 - accuracy: 0.9592 - val_loss: 0.2641 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1832 - accuracy: 0.9184 - val_loss: 0.2591 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1563 - accuracy: 0.9592 - val_loss: 0.2546 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1828 - accuracy: 0.9592 - val_loss: 0.2499 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1644 - accuracy: 0.9592 - val_loss: 0.2462 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1373 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1502 - accuracy: 0.9592 - val_loss: 0.2390 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1672 - accuracy: 0.9592 - val_loss: 0.2358 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2442 - accuracy: 0.9592 - val_loss: 0.2331 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1772 - accuracy: 0.9388 - val_loss: 0.2289 - val_accuracy: 0.9600\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1698 - accuracy: 0.9592 - val_loss: 0.2252 - val_accuracy: 0.9600\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1527 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9600\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1203 - accuracy: 0.9592 - val_loss: 0.2161 - val_accuracy: 0.9600\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9600\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1576 - accuracy: 0.9592 - val_loss: 0.2109 - val_accuracy: 0.9600\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.1778 - accuracy: 0.9184 - val_loss: 0.2086 - val_accuracy: 0.9600\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1616 - accuracy: 0.9592 - val_loss: 0.2071 - val_accuracy: 0.9600\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9388 - val_loss: 0.2055 - val_accuracy: 0.9600\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1462 - accuracy: 0.9388 - val_loss: 0.2043 - val_accuracy: 0.9600\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1443 - accuracy: 0.9388 - val_loss: 0.2031 - val_accuracy: 0.9600\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2068 - accuracy: 0.8776 - val_loss: 0.2014 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1733 - accuracy: 0.8980 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1217 - accuracy: 0.9592 - val_loss: 0.1943 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1556 - accuracy: 0.9592 - val_loss: 0.1922 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1349 - accuracy: 0.9388 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1397 - accuracy: 0.9184 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1589 - accuracy: 0.9388 - val_loss: 0.1845 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1445 - accuracy: 0.9796 - val_loss: 0.1827 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1205 - accuracy: 0.9796 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1518 - accuracy: 0.9184 - val_loss: 0.1765 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1286 - accuracy: 0.9388 - val_loss: 0.1746 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1235 - accuracy: 0.9592 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1324 - accuracy: 0.9592 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0941 - accuracy: 0.9796 - val_loss: 0.1735 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1010 - accuracy: 0.9796 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1513 - accuracy: 0.9388 - val_loss: 0.1751 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1171 - accuracy: 0.9796 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1805 - accuracy: 0.9388 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1186 - accuracy: 0.9592 - val_loss: 0.1822 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0798 - accuracy: 0.9796 - val_loss: 0.1841 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1111 - accuracy: 0.9592 - val_loss: 0.1859 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0971 - accuracy: 0.9796 - val_loss: 0.1866 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9388 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0826 - accuracy: 0.9796 - val_loss: 0.1777 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1153 - accuracy: 0.9388 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1069 - accuracy: 0.9592 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0596 - accuracy: 0.9796 - val_loss: 0.1536 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0978 - accuracy: 0.9592 - val_loss: 0.1454 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1363 - accuracy: 0.9592 - val_loss: 0.1423 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9600\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0833 - accuracy: 0.9796 - val_loss: 0.1353 - val_accuracy: 0.9600\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1313 - accuracy: 0.9592 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9388 - val_loss: 0.1325 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0877 - accuracy: 0.9796 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0874 - accuracy: 0.9796 - val_loss: 0.1309 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1060 - accuracy: 0.9796 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1014 - accuracy: 0.9796 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1334 - accuracy: 0.9592 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1045 - accuracy: 0.9592 - val_loss: 0.1262 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0957 - accuracy: 0.9796 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0954 - accuracy: 0.9592 - val_loss: 0.1249 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1162 - accuracy: 0.9592 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.9796 - val_loss: 0.1239 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1000 - accuracy: 0.9796 - val_loss: 0.1219 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9796 - val_loss: 0.1198 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1050 - accuracy: 0.9592 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1333 - accuracy: 0.9388 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1742 - accuracy: 0.9184 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0817 - accuracy: 0.9796 - val_loss: 0.1128 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0893 - accuracy: 0.9796 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0878 - accuracy: 0.9796 - val_loss: 0.1137 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0810 - accuracy: 0.9796 - val_loss: 0.1127 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1126 - accuracy: 0.9592 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.93 - 0s 0s/step - loss: 0.1004 - accuracy: 0.9592 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1077 - accuracy: 0.9388 - val_loss: 0.1088 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0849 - accuracy: 0.9796 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0640 - accuracy: 0.9796 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1153 - accuracy: 0.9592 - val_loss: 0.1079 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0833 - accuracy: 0.9796 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0784 - accuracy: 0.9796 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0694 - accuracy: 0.9796 - val_loss: 0.1106 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0976 - accuracy: 0.9796 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0795 - accuracy: 0.9592 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1045 - accuracy: 0.9388 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0941 - accuracy: 0.9592 - val_loss: 0.1035 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1032 - accuracy: 0.9796 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1117 - accuracy: 0.9592 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0646 - accuracy: 0.9796 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.9796 - val_loss: 0.0982 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0783 - accuracy: 0.9592 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0742 - accuracy: 0.9796 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c7b429640>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(x = X_train, y = y_train, validation_data = (X_test,y_test), epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_model.predict(x = X_values)\n",
    "# We run a one hot conversion that takes the\n",
    "# index of the largest value and sets that to\n",
    "# one, and the rest 0.\n",
    "def one_hot_conversion(obj, size = 6):\n",
    "    argmax = np.argmax(obj)\n",
    "    obj = np.zeros(shape = (size,))\n",
    "    obj[argmax] = 1\n",
    "    return obj\n",
    "\n",
    "# Using function one_hot_conversion()\n",
    "# to covert the Keras predictions into\n",
    "# one hot vectors.\n",
    "cluster = []\n",
    "for index, obj in enumerate(y_pred):\n",
    "    y_pred[index] = one_hot_conversion(obj, size = output_length)\n",
    "    cluster.append(np.argmax(y_pred[index]) + 1)\n",
    "anom_df['type'] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16c7c682a00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the data.\n",
    "marker_dict = {1:'x',\n",
    "               2:'|',\n",
    "               3:'_',\n",
    "               4:'.',\n",
    "               5:'+',\n",
    "               6:'1'}\n",
    "\n",
    "legend_labels = ['1) crustal thickening',\n",
    "                 '2) crustal thinning',\n",
    "                 '3) mantle thinning',\n",
    "                 '4) mantle thickening',\n",
    "                 '5) lithospheric thickening',\n",
    "                 '6) default configuration']\n",
    "\n",
    "groups = anom_df.groupby('type')\n",
    "for name, group in groups:\n",
    "    plt.plot(group['x (km)'],\n",
    "             group['Bouguer anom (mGal)'],\n",
    "             marker=marker_dict[name],\n",
    "             linestyle='',\n",
    "             markersize=10,\n",
    "             label=name,\n",
    "             color = (0,0,0))\n",
    "plt.xlabel(xlabel = 'x (km)')\n",
    "plt.ylabel(ylabel = 'Bouguer anom (mGal)')\n",
    "plt.legend(bbox_to_anchor = (1.05,1), loc = 'upper left', borderaxespad = 0, labels = legend_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00        47\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        74\n",
      "   macro avg       1.00      1.00      1.00        74\n",
      "weighted avg       1.00      1.00      1.00        74\n",
      " samples avg       1.00      1.00      1.00        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Network accuracy = {}'.format(accuracy_score(y_true = y_labels, y_pred = y_pred)))\n",
    "print(classification_report(y_true = y_labels, y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within or at 200 epochs, the ANN converges to the correct solution. We will quantify the difference of including the quadratic features that were very beneficial to the other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With quadratic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating quadratic features using\n",
    "# difference of two squares and cross terms.\n",
    "anom_df['f12(A,B)'] = anom_df['Airy anom (mGal)']**2 - anom_df['Bouguer anom (mGal)']**2\n",
    "anom_df['f12(B,G)'] = anom_df['Bouguer anom (mGal)']**2 - anom_df['Geoid anom (mGal)']**2\n",
    "anom_df['f12(A,G)'] = anom_df['Airy anom (mGal)']**2 - anom_df['Geoid anom (mGal)']**2\n",
    "anom_df['f22(A,B)'] = anom_df['Airy anom (mGal)']*anom_df['Bouguer anom (mGal)']\n",
    "anom_df['f22(B,G)'] = anom_df['Bouguer anom (mGal)']*anom_df['Geoid anom (mGal)']\n",
    "anom_df['f22(A,G)'] = anom_df['Airy anom (mGal)']*anom_df['Geoid anom (mGal)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_input_list = ['Airy anom (mGal)', 'Bouguer anom (mGal)', 'Geoid anom (mGal)',\n",
    "              'f12(A,B)', 'f12(B,G)', 'f12(A,G)', 'f22(A,B)', 'f22(B,G)', 'f22(A,G)']\n",
    "scaler = StandardScaler()\n",
    "X_values = scaler.fit_transform(anom_df[quad_input_list])\n",
    "y_labels = anom_df[type_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_values,\n",
    "                                                    y_labels,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(units = 50, input_dim = len(quad_input_list), activation = 'relu', name = 'hidden_layer_1'))\n",
    "keras_model.add(Dropout(rate = 0.25))\n",
    "keras_model.add(Dense(units = 50, activation = 'relu', name = 'hidden_layer_2'))\n",
    "keras_model.add(Dropout(rate = 0.25))\n",
    "keras_model.add(Dense(units = output_length, activation = 'softmax', name = 'output_layer'))\n",
    "keras_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3),\n",
    "                                                         loss = 'categorical_crossentropy',\n",
    "                                                         metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 2.1178 - accuracy: 0.0000e+00 - val_loss: 2.0248 - val_accuracy: 0.0400\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0312 - accuracy: 0.0000e+00 - val_loss: 1.9711 - val_accuracy: 0.0400\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8906 - accuracy: 0.0408 - val_loss: 1.9188 - val_accuracy: 0.0400\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8403 - accuracy: 0.1633 - val_loss: 1.8667 - val_accuracy: 0.1600\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7395 - accuracy: 0.1837 - val_loss: 1.8167 - val_accuracy: 0.2800\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7503 - accuracy: 0.3061 - val_loss: 1.7672 - val_accuracy: 0.3600\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6617 - accuracy: 0.5306 - val_loss: 1.7181 - val_accuracy: 0.4400\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6373 - accuracy: 0.4898 - val_loss: 1.6706 - val_accuracy: 0.5200\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5725 - accuracy: 0.5102 - val_loss: 1.6255 - val_accuracy: 0.5200\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.5355 - accuracy: 0.6122 - val_loss: 1.5812 - val_accuracy: 0.5600\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4438 - accuracy: 0.7143 - val_loss: 1.5372 - val_accuracy: 0.5600\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3423 - accuracy: 0.7551 - val_loss: 1.4933 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.4103 - accuracy: 0.6327 - val_loss: 1.4501 - val_accuracy: 0.6000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2567 - accuracy: 0.8367 - val_loss: 1.4078 - val_accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3000 - accuracy: 0.7755 - val_loss: 1.3656 - val_accuracy: 0.6000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1634 - accuracy: 0.8367 - val_loss: 1.3218 - val_accuracy: 0.6400\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1022 - accuracy: 0.8163 - val_loss: 1.2777 - val_accuracy: 0.6400\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.1047 - accuracy: 0.8163 - val_loss: 1.2322 - val_accuracy: 0.6400\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1114 - accuracy: 0.7959 - val_loss: 1.1878 - val_accuracy: 0.6400\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0691 - accuracy: 0.7959 - val_loss: 1.1441 - val_accuracy: 0.6400\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0144 - accuracy: 0.8163 - val_loss: 1.1014 - val_accuracy: 0.6400\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8905 - accuracy: 0.8163 - val_loss: 1.0591 - val_accuracy: 0.7200\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8380 - accuracy: 0.8367 - val_loss: 1.0184 - val_accuracy: 0.7200\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.9139 - accuracy: 0.8367 - val_loss: 0.9781 - val_accuracy: 0.7200\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8451 - accuracy: 0.8163 - val_loss: 0.9395 - val_accuracy: 0.7200\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7270 - accuracy: 0.8571 - val_loss: 0.9026 - val_accuracy: 0.7200\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7414 - accuracy: 0.8163 - val_loss: 0.8675 - val_accuracy: 0.7200\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.8571 - val_loss: 0.8344 - val_accuracy: 0.7200\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6491 - accuracy: 0.8571 - val_loss: 0.8032 - val_accuracy: 0.7200\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5643 - accuracy: 0.8367 - val_loss: 0.7738 - val_accuracy: 0.7200\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5301 - accuracy: 0.8980 - val_loss: 0.7462 - val_accuracy: 0.7200\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5746 - accuracy: 0.8571 - val_loss: 0.7200 - val_accuracy: 0.7200\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5148 - accuracy: 0.8571 - val_loss: 0.6958 - val_accuracy: 0.7200\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4716 - accuracy: 0.8776 - val_loss: 0.6738 - val_accuracy: 0.8400\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4348 - accuracy: 0.8980 - val_loss: 0.6525 - val_accuracy: 0.8400\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4546 - accuracy: 0.8571 - val_loss: 0.6318 - val_accuracy: 0.8800\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4367 - accuracy: 0.8980 - val_loss: 0.6114 - val_accuracy: 0.8800\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4471 - accuracy: 0.8367 - val_loss: 0.5917 - val_accuracy: 0.8800\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4011 - accuracy: 0.8571 - val_loss: 0.5733 - val_accuracy: 0.8800\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4061 - accuracy: 0.8776 - val_loss: 0.5558 - val_accuracy: 0.8800\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3679 - accuracy: 0.8776 - val_loss: 0.5391 - val_accuracy: 0.8800\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3281 - accuracy: 0.9184 - val_loss: 0.5219 - val_accuracy: 0.8800\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3740 - accuracy: 0.7959 - val_loss: 0.5063 - val_accuracy: 0.8800\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2826 - accuracy: 0.9592 - val_loss: 0.4914 - val_accuracy: 0.8800\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3272 - accuracy: 0.8980 - val_loss: 0.4773 - val_accuracy: 0.8800\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2965 - accuracy: 0.9184 - val_loss: 0.4631 - val_accuracy: 0.8800\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2826 - accuracy: 0.8776 - val_loss: 0.4496 - val_accuracy: 0.8800\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2547 - accuracy: 0.9184 - val_loss: 0.4369 - val_accuracy: 0.9200\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2712 - accuracy: 0.9184 - val_loss: 0.4244 - val_accuracy: 0.9200\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.2984 - accuracy: 0.9388 - val_loss: 0.4113 - val_accuracy: 0.9200\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2721 - accuracy: 0.8980 - val_loss: 0.3978 - val_accuracy: 0.9200\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2474 - accuracy: 0.9592 - val_loss: 0.3844 - val_accuracy: 0.9200\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2519 - accuracy: 0.9388 - val_loss: 0.3712 - val_accuracy: 0.9200\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2307 - accuracy: 0.9796 - val_loss: 0.3587 - val_accuracy: 0.9200\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3071 - accuracy: 0.9388 - val_loss: 0.3469 - val_accuracy: 0.9200\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2381 - accuracy: 0.9592 - val_loss: 0.3362 - val_accuracy: 0.9200\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2831 - accuracy: 0.9388 - val_loss: 0.3259 - val_accuracy: 0.9200\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2112 - accuracy: 0.9796 - val_loss: 0.3165 - val_accuracy: 0.9200\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1844 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9200\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1854 - accuracy: 0.9592 - val_loss: 0.2990 - val_accuracy: 0.9200\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2280 - accuracy: 0.9592 - val_loss: 0.2901 - val_accuracy: 0.9200\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9796 - val_loss: 0.2797 - val_accuracy: 0.9200\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2075 - accuracy: 0.9592 - val_loss: 0.2692 - val_accuracy: 0.9200\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1750 - accuracy: 0.9796 - val_loss: 0.2600 - val_accuracy: 0.9200\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2024 - accuracy: 0.9592 - val_loss: 0.2510 - val_accuracy: 0.9200\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9200\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1620 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9200\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2058 - accuracy: 0.9388 - val_loss: 0.2275 - val_accuracy: 0.9200\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1566 - accuracy: 0.9796 - val_loss: 0.2205 - val_accuracy: 0.9200\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1847 - accuracy: 0.9184 - val_loss: 0.2135 - val_accuracy: 0.9200\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1479 - accuracy: 0.9592 - val_loss: 0.2069 - val_accuracy: 0.9200\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 0.9592 - val_loss: 0.2005 - val_accuracy: 0.9200\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.9796 - val_loss: 0.1950 - val_accuracy: 0.9200\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1175 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9200\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1769 - accuracy: 0.9592 - val_loss: 0.1858 - val_accuracy: 0.9200\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1825 - accuracy: 0.9796 - val_loss: 0.1814 - val_accuracy: 0.9200\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1429 - accuracy: 0.9796 - val_loss: 0.1769 - val_accuracy: 0.9200\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1662 - accuracy: 0.9388 - val_loss: 0.1728 - val_accuracy: 0.9200\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9200\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1301 - accuracy: 0.9796 - val_loss: 0.1647 - val_accuracy: 0.9200\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9200\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1220 - accuracy: 0.9796 - val_loss: 0.1559 - val_accuracy: 0.9200\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1077 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9200\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9200\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1281 - accuracy: 0.9796 - val_loss: 0.1420 - val_accuracy: 0.9200\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9200\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0934 - accuracy: 0.9796 - val_loss: 0.1339 - val_accuracy: 0.9600\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1660 - accuracy: 0.9592 - val_loss: 0.1303 - val_accuracy: 0.9600\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1023 - accuracy: 0.9796 - val_loss: 0.1274 - val_accuracy: 0.9600\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0864 - accuracy: 0.9796 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1168 - accuracy: 0.9796 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1037 - accuracy: 0.9796 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1207 - accuracy: 0.9796 - val_loss: 0.1151 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1158 - accuracy: 0.9796 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0935 - accuracy: 0.9796 - val_loss: 0.1072 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0786 - accuracy: 0.9796 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1156 - accuracy: 0.9796 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0789 - accuracy: 0.9592 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.9796 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0831 - accuracy: 0.9592 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0814 - accuracy: 0.9796 - val_loss: 0.0819 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0803 - accuracy: 0.9796 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0568 - accuracy: 0.9796 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0694 - accuracy: 0.9796 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0540 - accuracy: 0.9796 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0964 - accuracy: 0.9796 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0648 - accuracy: 0.9592 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0732 - accuracy: 0.9796 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0414 - accuracy: 0.9796 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0341 - accuracy: 0.9796 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 0.9796 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 0.9796 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9796 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0424 - accuracy: 0.9796 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0512 - accuracy: 0.9796 - val_loss: 0.0249 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.0290 - accuracy: 0.9796 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0815 - accuracy: 0.9592 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0531 - accuracy: 0.9796 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0709 - accuracy: 0.9796 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c7f9ff670>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(x = X_train, y = y_train, validation_data = (X_test,y_test), epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_model.predict(x = X_values)\n",
    "\n",
    "# Using function one_hot_conversion()\n",
    "# to covert the Keras predictions into\n",
    "# one hot vectors.\n",
    "cluster = []\n",
    "for index, obj in enumerate(y_pred):\n",
    "    y_pred[index] = one_hot_conversion(obj, size = output_length)\n",
    "    cluster.append(np.argmax(y_pred[index]) + 1)\n",
    "anom_df['type (quad features)'] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16c7c6824c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = anom_df.groupby('type (quad features)')\n",
    "for name, group in groups:\n",
    "    plt.plot(group['x (km)'],\n",
    "             group['Bouguer anom (mGal)'],\n",
    "             marker=marker_dict[name],\n",
    "             linestyle='',\n",
    "             markersize=10,\n",
    "             label=name,\n",
    "             color = (0,0,0))\n",
    "plt.xlabel(xlabel = 'x (km)')\n",
    "plt.ylabel(ylabel = 'Bouguer anom (mGal)')\n",
    "plt.legend(bbox_to_anchor = (1.05,1), loc = 'upper left', borderaxespad = 0, labels = legend_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network accuracy = 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00        47\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        74\n",
      "   macro avg       1.00      1.00      1.00        74\n",
      "weighted avg       1.00      1.00      1.00        74\n",
      " samples avg       1.00      1.00      1.00        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Network accuracy = {}'.format(accuracy_score(y_true = y_labels, y_pred = y_pred)))\n",
    "print(classification_report(y_true = y_labels, y_pred = y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the quadratic features mainly has implications in reducing the number of epochs needed for convergence. Both methods do reach convergence with or without the inclusion of these features, but since these additional features improve convergence in other models I suggest one includes them in an ANN anyway. The additional quadratic features are easy to generate and improve accuracy in other models significantly, by allowing the model to assess the joint values of different anomalies together instead of merely looking at a single anomaly at a time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
